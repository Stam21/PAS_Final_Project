{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 4 cars, 69.4ms\n",
      "Speed: 5.4ms preprocess, 69.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 4 cars, 74.1ms\n",
      "Speed: 1.0ms preprocess, 74.1ms inference, 8.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 2 bicycles, 4 cars, 70.7ms\n",
      "Speed: 1.0ms preprocess, 70.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 4 cars, 77.5ms\n",
      "Speed: 1.8ms preprocess, 77.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 4 cars, 100.4ms\n",
      "Speed: 0.0ms preprocess, 100.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 4 cars, 61.3ms\n",
      "Speed: 0.0ms preprocess, 61.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 4 cars, 64.6ms\n",
      "Speed: 1.1ms preprocess, 64.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 2 bicycles, 4 cars, 69.1ms\n",
      "Speed: 1.0ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 4 cars, 82.2ms\n",
      "Speed: 1.0ms preprocess, 82.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 1 bicycle, 4 cars, 103.6ms\n",
      "Speed: 1.0ms preprocess, 103.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 82.8ms\n",
      "Speed: 0.9ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 81.1ms\n",
      "Speed: 1.9ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 78.3ms\n",
      "Speed: 1.1ms preprocess, 78.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 101.6ms\n",
      "Speed: 0.9ms preprocess, 101.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 94.3ms\n",
      "Speed: 1.0ms preprocess, 94.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 4 cars, 96.8ms\n",
      "Speed: 2.0ms preprocess, 96.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 81.1ms\n",
      "Speed: 1.9ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 3 cars, 74.9ms\n",
      "Speed: 1.2ms preprocess, 74.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 70.8ms\n",
      "Speed: 2.0ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 72.0ms\n",
      "Speed: 0.9ms preprocess, 72.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 3 cars, 67.8ms\n",
      "Speed: 1.1ms preprocess, 67.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 4 cars, 89.1ms\n",
      "Speed: 1.0ms preprocess, 89.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 12 persons, 5 cars, 84.2ms\n",
      "Speed: 2.0ms preprocess, 84.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 12 persons, 4 cars, 70.5ms\n",
      "Speed: 1.0ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 12 persons, 3 cars, 87.1ms\n",
      "Speed: 1.9ms preprocess, 87.1ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 3 cars, 94.0ms\n",
      "Speed: 1.9ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 4 cars, 68.5ms\n",
      "Speed: 0.9ms preprocess, 68.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 3 cars, 94.1ms\n",
      "Speed: 2.0ms preprocess, 94.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 2 cars, 71.3ms\n",
      "Speed: 2.0ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 4 cars, 95.2ms\n",
      "Speed: 2.0ms preprocess, 95.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 4 cars, 89.5ms\n",
      "Speed: 1.0ms preprocess, 89.5ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 3 cars, 88.7ms\n",
      "Speed: 1.0ms preprocess, 88.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 3 cars, 78.1ms\n",
      "Speed: 2.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 3 cars, 73.5ms\n",
      "Speed: 1.0ms preprocess, 73.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 3 cars, 73.5ms\n",
      "Speed: 1.0ms preprocess, 73.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 3 cars, 90.3ms\n",
      "Speed: 1.9ms preprocess, 90.3ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 85.5ms\n",
      "Speed: 2.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 2 cars, 93.1ms\n",
      "Speed: 1.0ms preprocess, 93.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 2 cars, 87.4ms\n",
      "Speed: 2.0ms preprocess, 87.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 2 cars, 74.0ms\n",
      "Speed: 1.0ms preprocess, 74.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 2 cars, 102.7ms\n",
      "Speed: 1.0ms preprocess, 102.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 2 cars, 81.3ms\n",
      "Speed: 1.9ms preprocess, 81.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 3 cars, 72.7ms\n",
      "Speed: 1.0ms preprocess, 72.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 4 cars, 67.7ms\n",
      "Speed: 1.0ms preprocess, 67.7ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 4 cars, 76.0ms\n",
      "Speed: 1.0ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 65.6ms\n",
      "Speed: 1.0ms preprocess, 65.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 5 cars, 87.0ms\n",
      "Speed: 0.9ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 76.3ms\n",
      "Speed: 1.0ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 4 cars, 76.6ms\n",
      "Speed: 0.9ms preprocess, 76.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 62.6ms\n",
      "Speed: 0.9ms preprocess, 62.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 4 cars, 66.9ms\n",
      "Speed: 2.0ms preprocess, 66.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 64.9ms\n",
      "Speed: 1.0ms preprocess, 64.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 76.3ms\n",
      "Speed: 2.0ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 5 cars, 90.8ms\n",
      "Speed: 1.6ms preprocess, 90.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 5 cars, 74.2ms\n",
      "Speed: 0.9ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 75.2ms\n",
      "Speed: 1.9ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 87.5ms\n",
      "Speed: 3.0ms preprocess, 87.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 5 cars, 85.2ms\n",
      "Speed: 0.9ms preprocess, 85.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 5 cars, 78.6ms\n",
      "Speed: 1.0ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 5 cars, 65.1ms\n",
      "Speed: 1.0ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 5 cars, 75.1ms\n",
      "Speed: 1.0ms preprocess, 75.1ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 75.8ms\n",
      "Speed: 2.0ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 3 cars, 65.4ms\n",
      "Speed: 2.0ms preprocess, 65.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 85.1ms\n",
      "Speed: 0.9ms preprocess, 85.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 2 cars, 85.5ms\n",
      "Speed: 1.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 1 bicycle, 4 cars, 64.2ms\n",
      "Speed: 2.0ms preprocess, 64.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 12 persons, 4 cars, 66.1ms\n",
      "Speed: 1.0ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 13 persons, 2 cars, 77.7ms\n",
      "Speed: 2.0ms preprocess, 77.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 2 cars, 99.2ms\n",
      "Speed: 1.0ms preprocess, 99.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 3 cars, 65.8ms\n",
      "Speed: 1.0ms preprocess, 65.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 3 cars, 95.8ms\n",
      "Speed: 1.0ms preprocess, 95.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 81.9ms\n",
      "Speed: 1.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 4 cars, 75.9ms\n",
      "Speed: 0.9ms preprocess, 75.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 84.8ms\n",
      "Speed: 1.0ms preprocess, 84.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 4 cars, 77.0ms\n",
      "Speed: 2.0ms preprocess, 77.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 4 cars, 64.4ms\n",
      "Speed: 2.0ms preprocess, 64.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 4 cars, 82.1ms\n",
      "Speed: 0.8ms preprocess, 82.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 90.6ms\n",
      "Speed: 1.0ms preprocess, 90.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 84.1ms\n",
      "Speed: 1.9ms preprocess, 84.1ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 2 bicycles, 4 cars, 98.4ms\n",
      "Speed: 1.0ms preprocess, 98.4ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 4 cars, 72.2ms\n",
      "Speed: 1.0ms preprocess, 72.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 4 cars, 76.0ms\n",
      "Speed: 1.0ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 4 cars, 101.9ms\n",
      "Speed: 2.0ms preprocess, 101.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 12 persons, 4 cars, 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 4 cars, 73.0ms\n",
      "Speed: 2.0ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 4 cars, 74.2ms\n",
      "Speed: 2.0ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 63.6ms\n",
      "Speed: 2.0ms preprocess, 63.6ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 62.2ms\n",
      "Speed: 1.0ms preprocess, 62.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 75.0ms\n",
      "Speed: 1.9ms preprocess, 75.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 4 cars, 67.5ms\n",
      "Speed: 1.0ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 4 cars, 84.9ms\n",
      "Speed: 2.0ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 105.0ms\n",
      "Speed: 0.9ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 14 persons, 4 cars, 65.5ms\n",
      "Speed: 1.0ms preprocess, 65.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 13 persons, 4 cars, 65.2ms\n",
      "Speed: 1.0ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 4 cars, 86.2ms\n",
      "Speed: 2.0ms preprocess, 86.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 13 persons, 4 cars, 87.8ms\n",
      "Speed: 1.0ms preprocess, 87.8ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 4 cars, 80.3ms\n",
      "Speed: 1.2ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 12 persons, 4 cars, 71.8ms\n",
      "Speed: 1.0ms preprocess, 71.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 12 persons, 4 cars, 105.3ms\n",
      "Speed: 1.0ms preprocess, 105.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 66.2ms\n",
      "Speed: 1.9ms preprocess, 66.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 4 cars, 71.5ms\n",
      "Speed: 0.9ms preprocess, 71.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 94.5ms\n",
      "Speed: 1.0ms preprocess, 94.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 87.6ms\n",
      "Speed: 0.9ms preprocess, 87.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 101.6ms\n",
      "Speed: 2.1ms preprocess, 101.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 86.3ms\n",
      "Speed: 0.9ms preprocess, 86.3ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 80.2ms\n",
      "Speed: 0.9ms preprocess, 80.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 68.7ms\n",
      "Speed: 1.0ms preprocess, 68.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 86.6ms\n",
      "Speed: 1.0ms preprocess, 86.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 72.2ms\n",
      "Speed: 2.4ms preprocess, 72.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 4 cars, 64.4ms\n",
      "Speed: 1.0ms preprocess, 64.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 87.9ms\n",
      "Speed: 2.9ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 4 cars, 104.8ms\n",
      "Speed: 2.0ms preprocess, 104.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 cars, 103.5ms\n",
      "Speed: 1.0ms preprocess, 103.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 74.7ms\n",
      "Speed: 0.9ms preprocess, 74.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 3 cars, 86.5ms\n",
      "Speed: 1.9ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 3 cars, 71.3ms\n",
      "Speed: 2.0ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 3 cars, 71.3ms\n",
      "Speed: 1.0ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 3 cars, 88.3ms\n",
      "Speed: 2.0ms preprocess, 88.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 2 cars, 70.4ms\n",
      "Speed: 1.1ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 3 cars, 100.4ms\n",
      "Speed: 1.0ms preprocess, 100.4ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 2 cars, 90.1ms\n",
      "Speed: 1.9ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 cars, 80.6ms\n",
      "Speed: 2.0ms preprocess, 80.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 1 bicycle, 2 cars, 99.6ms\n",
      "Speed: 1.0ms preprocess, 99.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 1 bicycle, 2 cars, 76.6ms\n",
      "Speed: 2.0ms preprocess, 76.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 13 persons, 1 bicycle, 2 cars, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 14 persons, 2 cars, 78.6ms\n",
      "Speed: 1.0ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 14 persons, 1 bicycle, 2 cars, 97.1ms\n",
      "Speed: 2.0ms preprocess, 97.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 14 persons, 1 bicycle, 2 cars, 67.0ms\n",
      "Speed: 0.9ms preprocess, 67.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 16 persons, 3 cars, 69.7ms\n",
      "Speed: 1.0ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 14 persons, 1 bicycle, 2 cars, 70.2ms\n",
      "Speed: 1.0ms preprocess, 70.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 15 persons, 1 bicycle, 1 car, 67.6ms\n",
      "Speed: 0.0ms preprocess, 67.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 12 persons, 1 bicycle, 1 car, 89.1ms\n",
      "Speed: 1.9ms preprocess, 89.1ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 2 bicycles, 2 cars, 83.5ms\n",
      "Speed: 1.0ms preprocess, 83.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 2 bicycles, 3 cars, 67.6ms\n",
      "Speed: 1.0ms preprocess, 67.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 3 bicycles, 4 cars, 70.7ms\n",
      "Speed: 1.0ms preprocess, 70.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 1 bicycle, 3 cars, 65.4ms\n",
      "Speed: 0.9ms preprocess, 65.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 2 bicycles, 3 cars, 65.2ms\n",
      "Speed: 1.0ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 2 bicycles, 2 cars, 88.7ms\n",
      "Speed: 2.3ms preprocess, 88.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 3 bicycles, 2 cars, 77.4ms\n",
      "Speed: 2.0ms preprocess, 77.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 3 bicycles, 2 cars, 110.5ms\n",
      "Speed: 2.0ms preprocess, 110.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 3 bicycles, 2 cars, 102.8ms\n",
      "Speed: 2.0ms preprocess, 102.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 2 bicycles, 3 cars, 64.1ms\n",
      "Speed: 1.9ms preprocess, 64.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 3 cars, 61.0ms\n",
      "Speed: 1.0ms preprocess, 61.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 4 cars, 90.1ms\n",
      "Speed: 1.0ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 4 cars, 69.0ms\n",
      "Speed: 2.1ms preprocess, 69.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 4 cars, 72.5ms\n",
      "Speed: 0.9ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 5 cars, 77.1ms\n",
      "Speed: 0.9ms preprocess, 77.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 4 cars, 72.5ms\n",
      "Speed: 2.0ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 4 cars, 61.8ms\n",
      "Speed: 1.0ms preprocess, 61.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 1 bicycle, 4 cars, 76.3ms\n",
      "Speed: 0.9ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 4 cars, 81.3ms\n",
      "Speed: 1.8ms preprocess, 81.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 4 cars, 71.2ms\n",
      "Speed: 2.0ms preprocess, 71.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 4 cars, 83.0ms\n",
      "Speed: 1.9ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 4 cars, 82.6ms\n",
      "Speed: 1.1ms preprocess, 82.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 5 cars, 69.6ms\n",
      "Speed: 0.9ms preprocess, 69.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 4 cars, 79.6ms\n",
      "Speed: 2.0ms preprocess, 79.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 5 cars, 86.4ms\n",
      "Speed: 2.0ms preprocess, 86.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 2 cars, 83.6ms\n",
      "Speed: 1.9ms preprocess, 83.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 3 cars, 73.0ms\n",
      "Speed: 1.0ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 3 cars, 75.1ms\n",
      "Speed: 0.9ms preprocess, 75.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 car, 99.7ms\n",
      "Speed: 1.0ms preprocess, 99.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 car, 79.5ms\n",
      "Speed: 1.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 car, 72.8ms\n",
      "Speed: 2.0ms preprocess, 72.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 71.9ms\n",
      "Speed: 2.0ms preprocess, 71.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 1 bicycle, 1 car, 70.5ms\n",
      "Speed: 1.0ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 car, 66.7ms\n",
      "Speed: 1.0ms preprocess, 66.7ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 3 cars, 66.7ms\n",
      "Speed: 2.2ms preprocess, 66.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 4 bicycles, 1 car, 79.2ms\n",
      "Speed: 1.0ms preprocess, 79.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 9 persons, 4 bicycles, 3 cars, 78.9ms\n",
      "Speed: 2.3ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 11 persons, 1 bicycle, 1 car, 79.9ms\n",
      "Speed: 0.0ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 2 bicycles, 89.2ms\n",
      "Speed: 2.2ms preprocess, 89.2ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 3 bicycles, 77.7ms\n",
      "Speed: 1.3ms preprocess, 77.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 4 bicycles, 3 cars, 79.8ms\n",
      "Speed: 0.0ms preprocess, 79.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 5 bicycles, 2 cars, 78.8ms\n",
      "Speed: 1.1ms preprocess, 78.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 3 bicycles, 4 cars, 91.5ms\n",
      "Speed: 7.8ms preprocess, 91.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 3 bicycles, 3 cars, 49.9ms\n",
      "Speed: 0.0ms preprocess, 49.9ms inference, 16.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 3 bicycles, 4 cars, 86.6ms\n",
      "Speed: 2.2ms preprocess, 86.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 3 bicycles, 2 cars, 73.4ms\n",
      "Speed: 1.1ms preprocess, 73.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 2 cars, 98.1ms\n",
      "Speed: 0.0ms preprocess, 98.1ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 2 cars, 67.3ms\n",
      "Speed: 0.0ms preprocess, 67.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 1 car, 99.1ms\n",
      "Speed: 0.0ms preprocess, 99.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 2 bicycles, 3 cars, 92.6ms\n",
      "Speed: 0.0ms preprocess, 92.6ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 3 cars, 52.1ms\n",
      "Speed: 1.3ms preprocess, 52.1ms inference, 7.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 2 cars, 94.9ms\n",
      "Speed: 0.0ms preprocess, 94.9ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 2 cars, 59.5ms\n",
      "Speed: 0.0ms preprocess, 59.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 3 cars, 65.5ms\n",
      "Speed: 0.0ms preprocess, 65.5ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 5 cars, 67.9ms\n",
      "Speed: 15.6ms preprocess, 67.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 4 cars, 67.4ms\n",
      "Speed: 0.0ms preprocess, 67.4ms inference, 7.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 5 cars, 83.9ms\n",
      "Speed: 1.4ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 3 cars, 68.1ms\n",
      "Speed: 2.0ms preprocess, 68.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 5 cars, 84.4ms\n",
      "Speed: 0.0ms preprocess, 84.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 4 cars, 55.7ms\n",
      "Speed: 0.0ms preprocess, 55.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 2 cars, 66.8ms\n",
      "Speed: 0.0ms preprocess, 66.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 2 cars, 82.0ms\n",
      "Speed: 0.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 2 cars, 66.7ms\n",
      "Speed: 1.9ms preprocess, 66.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 3 cars, 66.6ms\n",
      "Speed: 15.9ms preprocess, 66.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 3 cars, 51.3ms\n",
      "Speed: 1.1ms preprocess, 51.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 3 cars, 65.5ms\n",
      "Speed: 0.0ms preprocess, 65.5ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 3 cars, 59.7ms\n",
      "Speed: 1.1ms preprocess, 59.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 4 cars, 70.5ms\n",
      "Speed: 6.3ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 4 cars, 83.3ms\n",
      "Speed: 0.0ms preprocess, 83.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 4 cars, 66.2ms\n",
      "Speed: 1.3ms preprocess, 66.2ms inference, 15.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 4 cars, 67.0ms\n",
      "Speed: 0.0ms preprocess, 67.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 4 cars, 66.1ms\n",
      "Speed: 0.0ms preprocess, 66.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 4 cars, 69.1ms\n",
      "Speed: 1.0ms preprocess, 69.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 3 cars, 86.5ms\n",
      "Speed: 0.0ms preprocess, 86.5ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 3 cars, 75.2ms\n",
      "Speed: 9.0ms preprocess, 75.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 3 cars, 65.5ms\n",
      "Speed: 1.5ms preprocess, 65.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 3 cars, 53.8ms\n",
      "Speed: 1.1ms preprocess, 53.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from collections import defaultdict\n",
    "\n",
    "# Kalman Filter Class\n",
    "class KalmanFilter:\n",
    "    def __init__(self):\n",
    "        self.F = np.array([[1, 1], [0, 1]], dtype=np.float64)  # State transition matrix\n",
    "        self.H = np.array([[1, 0]], dtype=np.float64)         # Measurement matrix\n",
    "        self.Q = np.array([[0.01, 0], [0, 0.01]], dtype=np.float64)  # Process noise covariance\n",
    "        self.R = np.array([[0.1]], dtype=np.float64)          # Measurement noise covariance\n",
    "        self.P = np.eye(2, dtype=np.float64)                  # Initial state covariance\n",
    "        self.state = np.array([[0], [0]], dtype=np.float64)   # Initial state [disparity, disparity_velocity]\n",
    "\n",
    "    def predict(self):\n",
    "        self.state = self.F @ self.state\n",
    "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
    "        return self.state[0, 0]  # Return predicted disparity\n",
    "\n",
    "    def update(self, measurement):\n",
    "        y = measurement - self.H @ self.state\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
    "        self.state += K @ y\n",
    "        self.P = (np.eye(2) - K @ self.H) @ self.P\n",
    "\n",
    "# Initialize the YOLO model\n",
    "yolo = YOLO('yolov8s.pt')  # Assuming the model is yolov8\n",
    "\n",
    "# Initialize DeepSort tracker\n",
    "tracker = DeepSort(\n",
    "    max_age=35,\n",
    "    n_init=3,\n",
    "    max_cosine_distance=0.2,\n",
    "    nn_budget=None,\n",
    ")\n",
    "\n",
    "# Class-to-color mapping\n",
    "CLASS_COLORS = {\n",
    "    0: (0, 255, 0),  # Green for humans\n",
    "    1: (255, 0, 0),  # Blue for class 1\n",
    "    2: (0, 0, 255),  # Red for class 2\n",
    "}\n",
    "\n",
    "# Class-to-name mapping\n",
    "CLASS_NAMES = {\n",
    "    0: \"Person\",\n",
    "    1: \"Bike\",\n",
    "    2: \"Car\"\n",
    "}\n",
    "\n",
    "# Minimum bounding box dimensions (width and height in pixels)\n",
    "MIN_BBOX_WIDTH = 35\n",
    "MIN_BBOX_HEIGHT = 35\n",
    "\n",
    "# Camera parameters\n",
    "K = np.array([[9.863925e+02, 0.000000e+00, 7.020000e+02],\n",
    "              [0.000000e+00, 9.821423e+02, 2.588854e+02],\n",
    "              [0.000000e+00, 0.000000e+00, 1.000000e+00]])  # Intrinsic matrix\n",
    "B = 0.537  # Baseline (in meters)\n",
    "f = K[0, 0]  # Focal length (in pixels)\n",
    "\n",
    "# Function to calculate depth (z) from disparity\n",
    "def calculate_depth(disparity, baseline, focal_length):\n",
    "    if disparity == 0:  # Avoid division by zero\n",
    "        return float('inf')\n",
    "    return (focal_length * baseline) / disparity\n",
    "\n",
    "# Template matching function\n",
    "def find_disparity(template, search_line):\n",
    "    template_width = template.shape[1]\n",
    "    sad_values = np.zeros(search_line.shape[1] - template_width + 1)\n",
    "\n",
    "    # Slide the template over the search line\n",
    "    for start_pix in range(search_line.shape[1] - template_width + 1):\n",
    "        end_pix = start_pix + template_width\n",
    "        search_box = search_line[:, start_pix:end_pix]\n",
    "        sad = np.sum(np.abs(search_box.astype('float32') - template.astype('float32')))\n",
    "        sad_values[start_pix] = sad\n",
    "\n",
    "    # Find the position with the minimum SAD\n",
    "    position = np.argmin(sad_values)\n",
    "    return position\n",
    "\n",
    "# Paths to the folders containing the stereEo image sequence\n",
    "left_image_folder = 'img_rect/seq_02/image_02/data'\n",
    "right_image_folder = 'img_rect/seq_02/image_03/data'\n",
    "\n",
    "# Get sorted lists of image filenames\n",
    "left_image_files = sorted([f for f in os.listdir(left_image_folder) if f.endswith('.png')])\n",
    "right_image_files = sorted([f for f in os.listdir(right_image_folder) if f.endswith('.png')])\n",
    "\n",
    "# Ensure there are images to process\n",
    "if not left_image_files or not right_image_files:\n",
    "    print(\"No images found in the specified folders.\")\n",
    "    exit()\n",
    "\n",
    "# Dictionary to store Kalman filters for each track\n",
    "kalman_filters = defaultdict(KalmanFilter)\n",
    "\n",
    "for left_image_file, right_image_file in zip(left_image_files, right_image_files):\n",
    "    # Load the current pair of stereo frames\n",
    "    left_frame_path = os.path.join(left_image_folder, left_image_file)\n",
    "    right_frame_path = os.path.join(right_image_folder, right_image_file)\n",
    "    \n",
    "    left_frame = cv2.imread(left_frame_path)\n",
    "    right_frame = cv2.imread(right_frame_path)\n",
    "\n",
    "    if left_frame is None or right_frame is None:\n",
    "        print(f\"Failed to load image pair: {left_image_file}, {right_image_file}\")\n",
    "        continue\n",
    "\n",
    "    # Detect objects in the current frame\n",
    "    results = yolo(left_frame, stream=True, classes=[0, 1, 2]) # 0: human, 1: bike, 2: car\n",
    "    detections = []  # To store detections in DeepSort format\n",
    "    class_map = {}   # To map track IDs to class IDs\n",
    "\n",
    "    # Extract bounding boxes, confidence, and class ID\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(float, box.xyxy[0].cpu().numpy())\n",
    "            conf = float(box.conf[0].cpu().numpy())\n",
    "            cls = int(box.cls[0].cpu().numpy())\n",
    "\n",
    "            # Calculate bounding box width and height\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "\n",
    "            # Filter out small detections\n",
    "            if width < MIN_BBOX_WIDTH or height < MIN_BBOX_HEIGHT:\n",
    "                continue  # Ignore detections with small bounding boxes\n",
    "\n",
    "            # Convert to [left, top, width, height]\n",
    "            left, top = x1, y1\n",
    "            detections.append(([left, top, width, height], conf, cls))  # Include class ID\n",
    "\n",
    "    # Update DeepSort tracker\n",
    "    tracks = tracker.update_tracks(detections, frame=left_frame)\n",
    "\n",
    "    # Persistent class map for track IDs\n",
    "    class_map = {}  # {track_id: (class_id, confidence)}\n",
    "\n",
    "    # Define reasonable constraints for disparity and depth\n",
    "    min_disparity = 1e-6\n",
    "    max_disparity = 100  # Adjust based on expected scene\n",
    "    min_depth = 0.6  # Minimum depth in meters\n",
    "    max_depth = 30   # Maximum depth in meters\n",
    "\n",
    "    # Smoothing factor for depth predictions\n",
    "    alpha = 0.9\n",
    "    previous_depths = {}  # To store previous depths for smoothing\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "        x1, y1, x2, y2 = map(int, ltrb)\n",
    "        center_x = (x1 + x2) // 2\n",
    "        center_y = (y1 + y2) // 2\n",
    "\n",
    "        if track.time_since_update <= 1:\n",
    "            # Visible (updated) track\n",
    "            matched_detection = None\n",
    "            for det in detections:\n",
    "                bbox, conf, cls = det\n",
    "                det_x1, det_y1, det_w, det_h = bbox\n",
    "                det_x2, det_y2 = det_x1 + det_w, det_y1 + det_h\n",
    "\n",
    "                # Check if detection overlaps with the tracked bounding box\n",
    "                if det_x1 < x2 and det_x2 > x1 and det_y1 < y2 and det_y2 > y1:\n",
    "                    matched_detection = (cls, conf)\n",
    "                    break\n",
    "\n",
    "            # Update class_map with the most confident detection\n",
    "            if matched_detection:\n",
    "                detected_cls, detected_conf = matched_detection\n",
    "                if track_id not in class_map or detected_conf > class_map[track_id][1]:\n",
    "                    class_map[track_id] = (detected_cls, detected_conf)\n",
    "\n",
    "            # Retrieve class ID from class_map\n",
    "            cls, _ = class_map.get(track_id, (None, 0))\n",
    "\n",
    "            if cls is not None:\n",
    "                class_name = CLASS_NAMES.get(cls, \"Unknown\")\n",
    "                color = CLASS_COLORS.get(cls, (255, 255, 255))\n",
    "            else:\n",
    "                class_name = \"Unknown\"\n",
    "                color = (255, 255, 255)\n",
    "\n",
    "            # Calculate disparity\n",
    "            template_size = 15\n",
    "            x_start = max(0, center_x - template_size // 2)\n",
    "            x_end = min(left_frame.shape[1], center_x + template_size // 2)\n",
    "            y_start = max(0, center_y - template_size // 2)\n",
    "            y_end = min(left_frame.shape[0], center_y + template_size // 2)\n",
    "\n",
    "            template = left_frame[y_start:y_end, x_start:x_end]\n",
    "            search_line = right_frame[y_start:y_end, :]\n",
    "            disparity_position = find_disparity(template, search_line)\n",
    "            disparity = center_x - disparity_position\n",
    "\n",
    "            # Clamp disparity\n",
    "            disparity = max(min(disparity, max_disparity), min_disparity)\n",
    "\n",
    "            # Update Kalman filter\n",
    "            kalman_filters[track_id].update(np.array([[disparity]], dtype=np.float64))\n",
    "\n",
    "            # Calculate depth and handle invalid values\n",
    "            if disparity < min_disparity or disparity > max_disparity:\n",
    "                depth = previous_depths.get(track_id, 0)  # Use last valid depth\n",
    "            else:\n",
    "                depth = calculate_depth(disparity, B, f)\n",
    "\n",
    "            # Smooth depth prediction\n",
    "            if track_id in previous_depths:\n",
    "                depth = alpha * depth + (1 - alpha) * previous_depths[track_id]\n",
    "            previous_depths[track_id] = depth\n",
    "\n",
    "            # Clamp depth and fallback to last valid value\n",
    "            if depth < min_depth or depth > max_depth:\n",
    "                depth = previous_depths.get(track_id, 0)\n",
    "\n",
    "            # Draw bounding box for visible tracks\n",
    "            cv2.rectangle(left_frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(left_frame, f\"ID: {track_id}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "            if depth<30:\n",
    "                cv2.putText(left_frame, f\"{depth:.2f}m\", (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "            cv2.putText(left_frame, f\"{class_name}\", (x1, y2 + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        else:\n",
    "            # Predicted (occluded) track\n",
    "            disparity = kalman_filters[track_id].predict()\n",
    "\n",
    "            # Clamp disparity\n",
    "            disparity = max(min(disparity, max_disparity), min_disparity)\n",
    "\n",
    "            # Calculate depth and handle invalid values\n",
    "            if disparity < min_disparity or disparity > max_disparity:\n",
    "                depth = previous_depths.get(track_id, 0)\n",
    "            else:\n",
    "                depth = calculate_depth(disparity, B, f)\n",
    "\n",
    "            # Smooth depth prediction\n",
    "            if track_id in previous_depths:\n",
    "                depth = alpha * depth + (1 - alpha) * previous_depths[track_id]\n",
    "            previous_depths[track_id] = depth\n",
    "\n",
    "            # Clamp depth and fallback to last valid value\n",
    "            if depth < min_depth or depth > max_depth:\n",
    "                depth = previous_depths.get(track_id, 0)\n",
    "\n",
    "            # Retrieve class ID from class_map\n",
    "            cls, _ = class_map.get(track_id, (None, 0))\n",
    "\n",
    "            if cls is not None:\n",
    "                class_name = CLASS_NAMES.get(cls, \" \")\n",
    "            else:\n",
    "                class_name = \" \"\n",
    "\n",
    "            # Draw bounding box for occluded tracks\n",
    "            color = (200, 200, 200)  # Gray for occluded tracks\n",
    "            cv2.rectangle(left_frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(left_frame, f\"ID: {track_id} (predicted)\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "            if depth<30:\n",
    "                cv2.putText(left_frame, f\"{depth:.2f}m (predicted)\", (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "            #cv2.putText(left_frame, f\"{class_name} (predicted)\", (x1, y2 + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Show the frame in a live window\n",
    "    cv2.imshow(\"Live Tracking with Depth\", left_frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
